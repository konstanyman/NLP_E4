{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import wget\n",
    "import os\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### functions ###\n",
    "\n",
    "# load file\n",
    "def download_file(url, filename):\n",
    "    if not os.path.exists(filename):\n",
    "        wget.download(url, filename)\n",
    "    else:\n",
    "        print(f\"{filename} already exists. Skipping download.\")\n",
    "\n",
    "# read text file lines\n",
    "def read_lines(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb-positive.txt already exists. Skipping download.\n",
      "imdb-negative.txt already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "urlp = \"http://dl.turkunlp.org/TKO_7095_2023/imdb-positives.txt\"\n",
    "urln = \"http://dl.turkunlp.org/TKO_7095_2023/imdb-negatives.txt\"\n",
    "\n",
    "download_file(urlp, 'imdb-positive.txt')\n",
    "download_file(urln, 'imdb-negative.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with both text files\n",
    "\n",
    "# read text files\n",
    "pos_lines = read_lines('imdb-positive.txt')\n",
    "neg_lines = read_lines('imdb-negative.txt')\n",
    "\n",
    "# create dict of two lists\n",
    "imdb_dict = {\"text\": pos_lines + neg_lines, \"label\": [\"positive\"] * len(pos_lines) + [\"negative\"] * len(neg_lines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataset of the dictionary\n",
    "imdb_ds = datasets.Dataset.from_dict(imdb_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently we have a HuggingFace Dataset with text and labels. The first 25 000 instances are positive reviews and the last 25 000 are negative reviews. Next we have to shuffle and split the data into train, validation and test splits with roughly equal splits of positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "imdb_ds = imdb_ds.shuffle(seed=523834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split first into 80/20\n",
    "imdb_ds = imdb_ds.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then further split the test set into two\n",
    "imdb_ds[\"test\"] = imdb_ds[\"test\"].train_test_split(test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct DatasetDict\n",
    "imdb_ds['validation'] = imdb_ds['test']['train']\n",
    "imdb_ds['test'] = imdb_ds['test']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 40000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
